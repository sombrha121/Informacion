# âš¡ INSTALACIÃ“N RÃPIDA: IA ASISTENTE PARA TU PROYECTO

## ğŸ“‹ CHECKLIST RÃPIDO

### 1ï¸âƒ£ INSTALAR OLLAMA (5 minutos)
- [ ] Descargar desde https://ollama.ai
- [ ] Ejecutar instalador (siguiente, siguiente, siguiente)
- [ ] Verificar: `ollama --version` en PowerShell

### 2ï¸âƒ£ DESCARGAR MODELO IA (5 minutos)
```powershell
ollama pull mistral
```

Espera a que termine (50-100MB descarga)

### 3ï¸âƒ£ INICIAR OLLAMA
```powershell
ollama serve
```

DÃ©jalo ejecutando. VerÃ¡s:
```
listening on 127.0.0.1:11434
```

### 4ï¸âƒ£ INSTALAR GUZZLE EN LARAVEL
En otra ventana PowerShell, en tu proyecto:
```powershell
cd c:\laragon\www\Informacion
composer require guzzlehttp/guzzle
```

### 5ï¸âƒ£ COPIAR ARCHIVOS A TU PROYECTO

Los archivos estÃ¡n listos en:

**Backend:**
```
app/Services/AIService.php
app/Http/Controllers/AIAssistantController.php
```

**Vista:**
```
resources/views/ai/assistant.blade.php
```

**Rutas:** Ya agregadas en `routes/web.php`

### 6ï¸âƒ£ ACCEDER A LA INTERFAZ

1. Abre tu navegador
2. Ve a: `http://tu-proyecto.test/ia-asistente`
3. Â¡Comienza a usar!

---

## ğŸ¯ CASOS DE USO

### Usar como Administrador
```
1. Ir a /ia-asistente
2. Escribir una pregunta mÃ©dica
3. Elegir tipo: Pregunta, SÃ­ntomas o Tratamiento
4. Enviar y recibir anÃ¡lisis inteligente
```

### Integrar en otros mÃ³dulos
Puedes usar el servicio en cualquier controlador:

```php
use App\Services\AIService;

public function miMetodo()
{
    $ai = new AIService();
    $respuesta = $ai->responderPregunta("Â¿QuÃ© es la gripe?");
    return $respuesta;
}
```

---

## âš™ï¸ CONFIGURACIÃ“N AVANZADA

### Cambiar modelo
En `app/Services/AIService.php`:

```php
private $model = 'mistral'; // Cambiar a 'neural-chat' u otro

// Descargar otros modelos:
// ollama pull neural-chat
// ollama pull dolphin-mixtral
// ollama pull llama2
```

### Ajustar temperatura (creatividad)
```php
'temperature' => 0.7, // 0=respuestas exactas, 1=mÃ¡s creativo
```

---

## ğŸ”§ SOLUCIÃ“N DE PROBLEMAS

### âŒ Error: "Connection refused"
**SoluciÃ³n:** Ollama no estÃ¡ ejecutÃ¡ndose
```powershell
ollama serve
```

### âŒ Error: "Model not found"
**SoluciÃ³n:** Descargar el modelo
```powershell
ollama pull mistral
```

### âŒ Respuestas muy lentas
**SoluciÃ³n:** Cambiar a modelo mÃ¡s pequeÃ±o
```powershell
ollama pull neural-chat
```

Luego en AIService.php: `private $model = 'neural-chat';`

### âŒ "Permission Denied"
**SoluciÃ³n:** Ejecutar PowerShell como administrador

---

## ğŸ“Š ESTADÃSTICAS DEL SISTEMA

| Aspecto | Detalle |
|---------|---------|
| **Costo** | Gratuito |
| **Privacidad** | 100% Local |
| **Velocidad** | ~2-5 segundos por respuesta |
| **Modelo** | Mistral 7B |
| **RAM Requerida** | 8GB+ recomendado |
| **Almacenamiento** | ~4GB para el modelo |

---

## ğŸš€ SIGUIENTES PASOS

1. âœ… Instala Ollama
2. âœ… Copia los archivos
3. âœ… Ejecuta `ollama serve`
4. âœ… Instala Guzzle
5. âœ… Accede a `/ia-asistente`
6. âœ… Â¡Prueba el asistente!

---

## ğŸ“š RECURSOS

- DocumentaciÃ³n Ollama: https://ollama.ai
- Modelos disponibles: https://ollama.ai/library
- DocumentaciÃ³n completa: Ver `GUIA_OLLAMA_IA_LOCAL.md`

---

**Â¡Tu IA Asistente estÃ¡ lista! ğŸ‰**

Si tienes problemas, revisa la guÃ­a completa: `GUIA_OLLAMA_IA_LOCAL.md`
